# AWS DevDay 2018
https://www.twitch.tv/aws_jp_events2/clips?range=7d


https://clips.twitch.tv/SucculentFaithfulSparrowPipeHype
## Serverlessを極めるためにDynamoDBデータモデリングを極めよう
- 登壇者 サーバーワークス＋フリーランス、テルイ マサシさん

- Serverless要素はあまりないかも、DynamoDBがメイン
- DynamoDB使ってますか

- DynamoDB好きですか
  - 好き、普通、帰来
  - LambdaとRDSの愛称がわるいからDynamoつかっている
    - 何でRDSと相性悪いか？
    - コネクションモデル
      - 永続性
    - セキュリティ
      - 組み込みの弱い認証
        - 閉じられたネットワークになってしまう
      - VPC内へのアクセスコスト（とてもOLTPでは使えない（数秒～数十秒）

- 積極的にDynamo使っていこう
  - DyamoDB Best Practieces
    - 端的に言ってバイブル
    - これが理解できていればよい

  - わからないから不安
    - テーブル設計、インデックス設計どうやるの＿
    - ACIDトランザクションないのに大丈夫？
      - 結果整合性は大丈夫？
    - うまく性能を引き出すにはどうすればよい？
 
 - DynamoDBの基本
   - あえて分類するなら分散KVSというジャンルのNoSQL
   - Keyによる完全一致とindex検索が可能
   - フルマネージド
   - 無限の自動拡張ストレージ

- DynamoDBはどんなデータベースか？
  - Amazon's Dynamo を読むといいかも（Betterであって
  - キーのハッシュ値で分散
  - バックグランドで更新を後がちで同期
    - 結果整合性ベース
  - 書き込み・読み込みのQuorum数で整合性がきまる
    - キーを指定した読み込みは整合性担保される

- PartitonKeyに連番をふっても意味がない
 - 連番カウンターを作るとPartitionga偏る
   - Max＋1なんてもってのほか
 - 論理的に一位となる属性があるならそれを使う
   - なければUUIDのような衝突可能性が極小なランダム値でよい
   - sortもできないのでSnowFlakeのような順序性もいらない

- Partitonごとのキャパシティ
  - 3000RCU、1000wCU、index sizeが10GB
  - どれか一つでも超過するとPartitionが分割される
  - ぶんかつされると確保したユニットが均等に割り振られる
  - スロットリング時の一時ばーすとがある
    - 限定的なバースト

- ソートキーで使われているインデックスは B+Tree Index
  - リーフで横のつながりがある。
  - ソートキーは1つしか持てない（RDBのような複合ソートキーはNG）

- Partiton Keyで分散した中でSort Keyで整列


- PrimarySortKey, LSI
  - Partithon KEｙで分散したインスタンスにindexがこうちくされる
  - 一つのインスタンス内では同期的にindexも更新される
    - 強整合性が選択可能
  - Primary Sort Keyのリーフノードに実データのあどれすが格納されているイメージ
  - LSIは実データをもたないので重複可能

- GSI（Global Secondary Index）は実テーブル
  - 集合論による射影
  - GSIのPartition Keywoもとに分散
  - リーフノードに属性とParimary Key
  - ソート済みのデータの部分複製

- GSIが射影する属性オプション
  - KEY_ONKY:Primary Keyの値のみ
    - 一位になるような属性のキーがあればこれを使用するといい
  - INCLUDE:Primary Keyの値＋選択した属性
  - ALL：すべての属性
    - あまり使わないかも
  - GSIに含めた属性はPrimary Keyを引き直す必要がなくなる
    - 読み込みの効率化
    - 更新コストとのトレードオフ
    - MySQLやPostgreSQLでいう Convering Index、 Index Only Scanのイメージ

-GSIに対するクエリは結果整合性
  - メインテーブルとは別のPartitionで分散される
  - 更新は非同期で反映
  - 結果整合性って大丈夫なの？
    - RDSでいうリードレプリカのイメージ


- 上記はすべてRDBにある、仕組みをしれば実にシンプル
  - DynamoDBは癖がある ✖
  - RDBの癖がありすぎる 〇
    - RDBに洗脳されている？

- DynamoDBのデータモデリングは
  - データの配置を決めること
- データモデリングの考え方のポイント
  - スキーマレスの意味を考える
    - List、Mapがもてること？
    - あとから属性をしーむれるに追加できること？
    - A. なんでも突っ込める
  - Partition Keyで分散
  - 極論すると分ける意味がない、わけない方がキャパシティが管理しやすい
  - 設計が優れたアプリケーションでは、必要なテーブルは１つのみです！
    - ちょっと大げさかも。。。
  - GSIの個数制限（5コ）などもあるので、業務ドメイン毎に1つくらいの気持ち

- RDBとはアプローチが異なる
  - RDB
    - まずスキーマ
    - 正規化
    - それに対してどうアクセスするか（SQL）を考える
  - DYなも
    - スキーマレス
    - 非正規化
    - まずアクセスを考えて、それに合わせてデータを作る
    - アプリケーション毎に...

- ACIDトランザクションないけど。。。どうなの
  - ACIDとは
    - 原子性、一貫性、独立性、永続性を担保するのがACID

  - ACIDの担保は
    - RDB
      - 正規化していくとテーブルの数は基本的には増える
      - 論理的に分かれたテーブル（レコード）間の整合性を取る仕組みがある
        
    - DynamoDB
      - 非正規化して１つの実態について１つのアイテムを収める
      - 1アイテム1テーブル

  - DynamoDBのデータの更新方法
    - PutItem
      - アイテムをまるごと更新する、なかったら作る
      - Get → 書き換え → Put だと独立性が崩れる
    - UpdateItem
      - アイテムを部分更新、なかったら作る
      - List,Mapの部分追加、削除も可能
      - 属性の値を利用した更新も可能（ある属性に＋１する等）
      - 属性の値を利用した条件付き書き込み

  - 非正規化すると読み込みがつらい
    - 全部GSIはるの。。。
    - ネストしたList、Mapはフルスキャンしかないの？

  - CQRS（Command Query Responsibility Segregation）
    - 書き込むデータと読み込むデータは同じである必要はない
      - 結果整合性を受け入れて非同期で読み込みデータを作れる
    - Commandの完了をもってQuery用データを作れる
      - DynamoDB Streamsがマッチ
      - CQRSを素直に実装するとKinesis Streamsだけど
      - Materialized
    ― AppSyncがキーかも

  - とはいえ限界もある
    - 複数の実態にまたがるトランザクションは厳しい
      - DynamoDBたんたいだとつらい
    - トランザクション分離レベルの最高はSelializeble
      - つまり直列化
      - Kinesis Streamsで直列化
- Adanced Tips
  → 写真に

  Sort Keyで前方一致検索が使えるかも。。。


- ブログいいかも
  - DynamoDB 虎の巻「検索」










    

## 2. Amazon DynamoDBとAmazon Payで実現するキャッシュレス社会
- スキップ



## 3. DockerとAmazon SageMakerで実現した機械学習システムのプロダクション移行
### 登壇者
島田 達朗 氏
コネヒト株式会社 共同創業者, 取締役CTO

昨年 TV CM を放映した、日本最大級のママ向けサービスである「ママリ」ではコミュニティサイトの治安を維持するために、自然言語処理と機械学習と用いて、コミュニティに投稿される不適切な投稿を検知するシステムが存在しています。
本講演では元々Amazon EC2 環境で稼働していた機械学習基盤を、今年 6 月に東京リージョンで提供が開始されたAmazon SageMaker に移行した過程と、その結果得られた知見について詳説を行います。

Connehito inc. CTO @tatsushim
- 運営しているサービス
  - ママリ、ママ向けNo1アプリ
    - 年間に出産するママの3人に1人が登録しているみたい
  - コミュニティーサイト
  - バックボーンでは機械学習でできている
    - 

- 資料は後で公開する

### コンテンツ
- 機械学習専門のエンジニア
- インフラ or アプリのエンジニア

### ママリの機械学習の活用事例
- 課題、コミュニティQAサイト
  - 出会い系業者など不正な業者をシャットアウト
  - コミュニティの雰囲気がとても大事
  - 少人数でスタートアップには、目視でかくにんできるリソース無し
- 解決方法
  質問フィルタリングで業者をシャットアウト
  - インフラ構成 ALB → ECS（API Server) migi  RDS → SQS ← EC  2(CRON） →EC2（ML）F（ｑ）
  - それぞれのアプリをSQSで疎にしている

### Docker ✖ SageMakerでの機械学習システム移行
- 移行前の課題
  MLがはいったEC2
  - 環境が2年前のもので古い
  - 開発環境がいけていなかった
  - VirtualBOX
  - プロビジョニングはAnsible

  - いきなりVMがこわれた

  - 大規模データで学習、モデル作成
  - 学習、推論ともにEC2を使用
  - 学習用のEC2はコンソールでポチポチ
    - EC2の管理が大変
  - 機械学習のエンジニアがインフラのことを意識しなきゃならなかった



- 理想の形を考えた
  - 開発者はコマンド一つくらいのレベルで、さっとローカル環境を立ち上げたれる
  - 誰でも同じ環境が立てられる
　　　↓
- Docker を導入した
  - コンテナなら環境の作り直しもらく
  - VMにくらべてCPU圧迫しない
  - ローカルの環境を曽於ママ本番にもってけるので環境債がなかった

- 学習・推論時にEC2管理をしたくない
　　　↓
- SageMaker
  - 機械学習のマネージドサービス
  - 豊富なビルトインあるゴリ済みがはいっている
  - Dockerイメージを実行することもできる
  - ママリのケースでは、既存環境の移行からDocker イメージを利用

- 実際に取り組んだこと
  - 移行方針はリフト＆シフトで既存環境を新環境をそのまま持っていく（Lift）
  - 移行後に随時変更（Shift）していく
  - 以下月で移行できたみたい。。。

- Lift&Shiftのメリット
  - スライドに
  - スモールスタートに向いている

- 環境の移行
  - Ansibleのコードをひたすら Dockerfile に天気
  - うまく動かないものはコンテナに入って検証
  - そもそもAnsibleで書いたプロビジョニングコードが年単位で前のものだとエラーがでる

- 機械学習をSageMakerに移行
  - 既存の構成は Scilit-lean + Flask のシンプル構成
  - 実態は Pythonファイル
  - サンプルに train、serveコマンドの例がある
  - もちろんローカル環境でテストも可能

- SageMakerで日本語を扱う際の課題
  - MeCabが利用できない
    - Docker Imamge でMecCabをいれてSageMakerにあげる

  - エンドポイントアクセスの認証が必要
    - SageMakerでエンドポイントをたたくには認証が必要
      - API Gateway とLambdaを挟んで、Lambda側で認証や差分を吸収してSageMakerを利用
      - Lambdaに付与するポリシーが必要
      - LambdaからSDKを用いたアクセス（Pythonで4行くらい）


### SageMakerへ移行して分かったころ
- メリット
  - 一度構築して Sagemaker way に載れば、運用はAWS側に任せられる
  - ツールに普段のフローを合わせることで生産性を高めることができる
  - 長いものにまかれる

  - 特に推論（APIエンドポイントの提供）に付随する機能が便利
  - モデルの切り替えもダウンタイム無し
  - 新旧モデルのABテストも可能
  - レスポンスヘッダーに詳細を返すのでそこからロギングする必要がある

  - SageMaker で作るフローの定式化（整理される）
    - 機械学習エンジニアによるオレオレ環境問題の解の１つ
    - SageMakerに沿うと自然に作業が疎になる
    - フローが定式化されることで分担しやすくなり、作業が整理される

- 個人的に思うこと
  - インフラやアプリの理解があり、機械学習を活用できる人はとても貴重になる
  - SageMakerがでたｔことで、双方向に取り組みやすくなった
  - 機械学習を利用するのが当たり前になるのでは...

- これから
  - ママ向けNo1あぷりとなり、行政との取り組みや社会への発信も行っている
  - 社会のインフラに近づきつつある中でサービスのコアテクノロジーになりたい
  - 非連続な成長を機械学習で創る
    - 日本の3人に1人が使うサービスのデータは研究対象としても貴重








## 4. Amazon SageMakerで実現する生産瑛の高い機械学習基盤
### 登壇者
南 直 氏
Wantedly株式会社 Infrastructure Engineer

Wantedly People の「名刺データ読み取り」機能など、Wantedly では様々な機能に機械学習を活用しています。
機械学習を取り入れた開発を生産性高く進める為に、私たちは機械学習基盤を整備してきました。その基盤の一部には、Amazon SageMaker を利用しています。
このセッションでは、Amazon SageMaker の活用方法を中心に、私たちの機械学習基盤についてお話いたします。


### 社内の機械学習の活用
- WANTEDLY VISIT いろいろな企業へ話を聞ける
  - ユーザーに対する企業のマッチング
  - 企業に対して候補者の推薦
- Wantedly People 名刺管理サービス
  - 名刺を通してリレーションも管理できるサービス
  - 名刺画像の読み取りロジック
    - 複数の名刺も読み取れる（数秒）
  - ユーザー同士のつながりロジック

### 社内の機械学習基盤の活用
- 機会学習機基盤の全体像
  以前はAmazon SageMaker導入以前から整備していた
    - エンジニアは3人ほど、決して多くない
    - データ基盤
      - BigQuery + S3
    - 開発＆学習
      - Local PC ＋ GPU instance
    - 評価
     - evという自社製のOSSの評価データ管理ツールを利用
    - デプロイ
      - Kubernatesを活用
      - Schedule job 指定した時刻に指定したイメージを実行することができる
    - 計測
      - データ基盤がととのっているため、ログ収集＋A/Bテストが可能

- aamzon SageMaker 導入以前の課題
  - 機械学習の開発＆学習にレールがないため、つらい！
    - 開発環境構築が負担
      - 環境セットアップが面倒
      - リソースアクセスの権限設定が面倒

    - 学習データ、モデルデータの扱いに厳格なルールがない
      - s3へデータは一はエンジニア次第になっていた

### Amazon SageMakerの活用
- Aamzon SageMaker とは
  - 機械学習を開発、学習、デプロイの３つのフェーズに分解。この3つのフェーズを提供するサービス
    - 開発、Notebook instance
      - Jupyter NoteBook
    - 学習 Training instance
    - デプロイ Hosting instance
      - SagemakerだけでAPIを立てられる

  - Wantedlyでは開発と学習に力をいれた


- Aamzon SageMaker 導入してみて
  - よかった

  - 開発
    - 環境構築がはやくなった
  - 学習
    - 額種データやモデルデータをs3にするぜんていで設計されている
    - 学習データがs3条にのこって、再現性が確保できる

  - その他
    - 開発であればインスタンスを低コストで利用できる
      - Notebook Instance 1か月上げっぱなしでも、 ml.t2.midium       3800/月
      - Notebook instanceを動くドキュメントとしてりようできた
      - Training instance はdockerで自由に学習環境を用意できた
         - DockerfileをかいてECRへpushすればDockerimageが利用できる
      - SageMakerが提供するパーツは、必要な部分だけを選択的に利用できる
         - 必要な部分だけ利用できるため、導入のハードルがさがった
      - SageMakerを前提にテンプレートの整備がすすめられた
        - 同じ環境で動くことを前提に手コードがきさいされた


  - 導入時は、インフラエンジニアと機械学習エンジニアの強豪
    - まずは試しに使ってい見る。
    - ソリューションアーキテクトに聞いてみた

    - 権限管理や運用ぽりしーを決める
      - インスタンスにiamをアタッチするので iam roleの作成や管理ポリシーの決めが必要
    - あとは、機械学習エンジニアの人に使ってもらいながら環境を整備
    - 実際に機械学習開発を SageMakerで進めてもらった
    - 開発＆学習をSageMakerで簡潔できる事を確認する
      - 分析から開発、学習、モデルデータの出力まで

  - 注意点＆Tips
    - Notebook Instance での開発時のTips
      - ~/SageMaker 以下に必要はファイルは配置する
      - メモリの使い過ぎに注意
        - 再起動で解消するが実用的じゃないので。。。工夫が必要
      - DiskはEFSの利用が推奨
    - 
  - 学習時の注意＆Tips
    - Try & Error ではlocal modeでの学習が必要
    - custom docker image を利用するときは /opt/ml の挙動を理解するべき  

- SageMaker開発した成果は
  - 3つの機械学習プロジェクトがプロダクション環境にリリース済み
    - 7月に検証、8月から本格運用開始できた

  - ユーザ同士のつながり推定
    - DeepWalkという手法を利用
      - ランダムウォークで学習して、word2vecで学習
  




## 5. Micro Frontendsの理論と実践－価値提供を高速化する真のマイクロサービスのあり方－